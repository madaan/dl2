{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/part2\")\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(nb_epoch=5):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print('nb sequences:', len(sentences))\n",
    "\n",
    "    print('Vectorization...')\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "    print('Build model...')\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=nb_epoch)\n",
    "    model.save_weights(\"nt_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_at = \"nt_weights\"\n",
    "if not os.path.exists(weights_at):\n",
    "    train(20)\n",
    "model.load_weights(\"nt_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def next_given_seed(seed, model):\n",
    "    generated = ''\n",
    "    i, num_spaces = 0, 0\n",
    "    while num_spaces < 1:\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(seed):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.2)\n",
    "        next_char = indices_char[next_index]\n",
    "        if next_char == ' ' and i > 0:\n",
    "            num_spaces += 1\n",
    "        generated += next_char\n",
    "        seed = seed[1:] + next_char\n",
    "        i += 1\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_blanks(incomplete, debug=False):\n",
    "    model.load_weights(\"nt_weights\")\n",
    "    words = incomplete.split(\" \")\n",
    "    complete = ''\n",
    "    blanks = {}\n",
    "    blank_i = 0\n",
    "    i, step = 0, 0\n",
    "    for word in words:\n",
    "        #print(step, i, complete)\n",
    "        if word == \"_\":\n",
    "            seed = complete[i - maxlen:i]\n",
    "            filled_word = next_given_seed(seed, model)\n",
    "            blanks[blank_i] = filled_word\n",
    "            if debug:\n",
    "                print(\"seed = {0}, generated = {1}\".format(seed, filled_word))\n",
    "            complete = complete + \" \" + filled_word\n",
    "            i = i + len(filled_word) + 1\n",
    "            blank_i += 1\n",
    "        else:\n",
    "            i = i + len(word) + 1\n",
    "            complete = complete + \" \" + word\n",
    "    return blanks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if winter comes, the poet shelley asked, \"can spring be \u001b[1m\u001b[43m the \u001b[0m behind?\"for the best part of a decade the \u001b[1m\u001b[43m theory \u001b[0m as far as the world economy has been concerned has been an increasingly weary \"yes it can\". now, though, after testing the faith of the most \u001b[1m\u001b[43m probably \u001b[0m souls with \u001b[1m\u001b[43m the \u001b[0m that came to nothing, things seem to be warming up. it looks \u001b[1m\u001b[43m to \u001b[0m that this year, for the \u001b[1m\u001b[43m standard \u001b[0m time since 2010, rich-world and \u001b[1m\u001b[43m the \u001b[0m economies will put on synchronised growth spurts.\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored, cprint\n",
    "#txt = \"this is a long sentence, there are many like this in the _ but this one is mine.\\\n",
    "#And why _ it not be? There are little _ in life that can do without such _ hype. Perhaps I read _ too much \\\n",
    "#into the ordeal of the world.\"#open(\"sample.txt\").read().lower()\n",
    "txt_original = \"IF WINTER comes, the poet Shelley asked, \\\"can Spring be far behind?\\\"\\\n",
    "For the best part of a decade the answer as far as the world economy has been\\\n",
    "concerned has been an increasingly weary \\\"Yes it can\\\". Now, though, after testing\\\n",
    "the faith of the most patient souls with glimmers that came to nothing, things seem\\\n",
    "to be warming up. It looks likely that this year, for the first time since 2010,\\\n",
    "rich-world and developing economies will put on synchronised growth spurts.\"\n",
    "\n",
    "txt = \"IF WINTER comes, the poet Shelley asked, \\\"can Spring be _ behind?\\\"\\\n",
    "For the best part of a decade the _ as far as the world economy has been \\\n",
    "concerned has been an increasingly weary \\\"Yes it can\\\". Now, though, after testing \\\n",
    "the faith of the most _ souls with _ that came to nothing, things seem \\\n",
    "to be warming up. It looks _ that this year, for the _ time since 2010, \\\n",
    "rich-world and _ economies will put on synchronised growth spurts.\"\n",
    "\n",
    "\n",
    "txt = txt.lower()\n",
    "CRED = '\\033[91m'\n",
    "CEND = '\\033[0m'\n",
    "#generate(\"this is a beautiful life it really is amazing and full of\")\n",
    "res = []\n",
    "blanks = fill_blanks(txt)\n",
    "blanks_i = 0\n",
    "for word in txt.split(\" \"):\n",
    "    if word == \"_\":\n",
    "        res.append(colored(blanks[blanks_i], on_color='on_yellow', attrs=['bold']))\n",
    "        \n",
    "        #print(CRED + blanks[blanks_i] + CEND, end=' ')\n",
    "        blanks_i += 1\n",
    "    else:\n",
    "        res.append(word)\n",
    "        #print(word, end=' ')\n",
    "print(\" \".join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
